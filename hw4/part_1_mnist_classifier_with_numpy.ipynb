{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of numpy_nn_2.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.0 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "ac2eaa0ea0ebeafcc7822e65e46aa9d4f966f30b695406963e145ea4a91cd4fc"
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YuxingW/deep_learning/blob/main/hw4/part_1_mnist_classifier_with_numpy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bja7Nwp-p6uc"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcYNkPmvymUP"
      },
      "source": [
        "###Three dimention data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SB0gwdPdBk5H"
      },
      "source": [
        "####MSE function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLE2kWrwBohl"
      },
      "source": [
        "class MSE:\n",
        "  def __call__(self, y_pred, y_true):\n",
        "    self.y_pred = y_pred\n",
        "    self.y_true = y_true\n",
        "    return ((y_pred - y_true) ** 2).mean()\n",
        "\n",
        "  def backward(self):\n",
        "    n = self.y_true.shape[0]\n",
        "    self.gradient = 2. * (self.y_pred - self.y_true) / n\n",
        "    #print('MSE backward', self.y_pred.shape, self.y_true.shape, self.gradient.shape)\n",
        "    return self.gradient"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLk9IANHpw-P"
      },
      "source": [
        "#### Fit fuction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQaMOSGPpxFx"
      },
      "source": [
        "from typing import Callable\n",
        "\n",
        "def fit(x: np.ndarray, y: np.ndarray, model: Callable, loss: Callable, lr: float, num_epochs: int):\n",
        "  for epoch in range(num_epochs):\n",
        "    y_pred = model(x)\n",
        "    loss_value = loss(y_pred, y)\n",
        "    if epoch % 200 == 0:\n",
        "      print(f'Epoch {epoch}, loss {loss_value}')\n",
        "    gradient_from_loss = loss.backward()\n",
        "    model.backward(gradient_from_loss)\n",
        "    model.update(lr)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbNQS_vyRuwu"
      },
      "source": [
        "batch_size = 100\n",
        "\n",
        "def fit_by_batch(x: np.ndarray, y: np.ndarray, x_test: np.ndarray, y_test: np.ndarray, model: Callable, loss: Callable, lr: float, num_epochs: int):\n",
        "  for epoch in range(num_epochs):\n",
        "    correct_cnt = 0\n",
        "    for i in range(int(len(x) / batch_size)):\n",
        "      batch_start, batch_end = ((i * batch_size), ((i+1)*batch_size))\n",
        "      x_batch = x[batch_start: batch_end]\n",
        "      y_batch = y[batch_start: batch_end]\n",
        "      y_pred_batch = model(x_batch)\n",
        "      loss_value = loss(y_pred_batch, y_batch)\n",
        "      gradient_from_loss = loss.backward()\n",
        "      model.backward(gradient_from_loss)\n",
        "      model.update(lr)\n",
        "      for k in range(batch_size):\n",
        "        correct_cnt += int(np.argmax(y_pred_batch[k:k+1]) == np.argmax(y_batch[k:k+1]))\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "      test_correct_cnt = 0\n",
        "      y_pred_test = model(x_test)\n",
        "      for k in range(len(y_test)):\n",
        "        test_correct_cnt += int(np.argmax(y_pred_test[k:k+1]) == np.argmax(y_test[k:k+1]))\n",
        "      print(f'Epoch {epoch},loss {loss_value}, correct_rate {correct_cnt/float(len(y))}, test_correct_rate {test_correct_cnt/float(len(y_test))}')\n",
        "\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2DS-bnPoxUB"
      },
      "source": [
        "#### Plot tsne function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rb7hnNNoxce"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "def plot_comparison(y_true, y_pred):\n",
        "  #tsne = TSNE(n_components=2, perplexity=50, learning_rate=100, random_state=120)\n",
        "  tsne = TSNE(n_components=2, random_state=0)\n",
        "  x_2d = tsne.fit_transform(x)\n",
        "  yt_2d = tsne.fit_transform(y_true)\n",
        "  yp_2d = tsne.fit_transform(y_pred)\n",
        "\n",
        "  plt.figure(figsize=(6, 5))\n",
        "  plt.scatter(yt_2d[:, 0], yt_2d[:, 1], c='b', label='y_true')\n",
        "  plt.scatter(yp_2d[:, 1], yp_2d[:, 1], c='y', label='y_pred')\n",
        "  plt.legend()\n",
        "  plt.title('TSNE Y_True Y_Pred Comparison')\n",
        "  plt.xlabel('t_SNE1')\n",
        "  plt.xlabel('t_SNE2')\n",
        "  plt.show()\n",
        "\n",
        "def plot_distribution(x, y_true, y_pred):\n",
        "  tsne = TSNE(n_components=1, random_state=0)\n",
        "  x_2d = tsne.fit_transform(x)\n",
        "  yt_2d = tsne.fit_transform(y_true)\n",
        "  yp_2d = tsne.fit_transform(y_pred)\n",
        "\n",
        "  plt.figure(figsize=(6, 5))\n",
        "  plt.scatter(x_2d[:, 0], yt_2d[:, 0], c='b', label='y_true')\n",
        "  plt.scatter(x_2d[:, 0], yp_2d[:, 0], c='y', label='y_pred')\n",
        "  plt.legend()\n",
        "  plt.title('TSNE Y_True Y_Pred Distribution with X')\n",
        "  plt.show()\n",
        "\n",
        "def plot_3d(x, y, y_pred=None):\n",
        "  import matplotlib.pyplot as plt\n",
        "  from mpl_toolkits.mplot3d import Axes3D\n",
        "  fig = plt.figure()\n",
        "  ax = fig.add_subplot(111, projection='3d')\n",
        "  ax.scatter(x[:, 0], x[:, 1], y, label='y_true')\n",
        "  if y_pred is not None:\n",
        "    ax.scatter(x[:, 0], x[:, 1], y_pred, label='y_pred')\n",
        "  plt.legend()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dnkJttUoQNm"
      },
      "source": [
        "####Linear model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVA2iu1koQkO"
      },
      "source": [
        "class Linear:\n",
        "  def __init__(self, input_dim: int, num_hidden: int = 1):\n",
        "    self.weights = np.random.randn(input_dim, num_hidden) * np.sqrt(2. / input_dim)\n",
        "    self.bias = np.zeros(num_hidden)\n",
        "  \n",
        "  def __call__(self, x):\n",
        "    self.x = x\n",
        "    output = x @ self.weights + self.bias\n",
        "    return output\n",
        "\n",
        "  def backward(self, gradient):\n",
        "    self.weights_gradient = self.x.T @ gradient\n",
        "    self.bias_gradient = gradient.sum(axis=0)\n",
        "    self.x_gradient = gradient @ self.weights.T\n",
        "    return self.x_gradient\n",
        "\n",
        "  def update(self, lr):\n",
        "    self.weights = self.weights - lr * self.weights_gradient\n",
        "    self.bias = self.bias - lr * self.bias_gradient"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_Q3msi8501n"
      },
      "source": [
        "#### Non-Linear model generation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEABFne4oqZe"
      },
      "source": [
        "3 layers neural network using relu nonlinearity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_kfAg4u5rrg"
      },
      "source": [
        "class Relu:\n",
        "    def __call__(self, input_, dropout_rate=0):\n",
        "        if dropout_rate > 0:\n",
        "          dropout_mask = np.random.binomial(1, 1-dropout_rate, size=input_.shape)\n",
        "          input_ *= dropout_mask * 2\n",
        "        self.input_ = input_\n",
        "        self.output = np.clip(self.input_, 0, None)\n",
        "        return self.output\n",
        "    \n",
        "    def backward(self, output_gradient):\n",
        "      # import pdb; pdb.set_trace()  # By the way, this is how you can debug\n",
        "      self.input_gradient = (self.input_ > 0) * output_gradient\n",
        "      return self.input_gradient\n",
        "\n",
        "class Model:\n",
        "  def __init__(self, input_dim, num_hidden, ouput_dim):\n",
        "    self.linear1 = Linear(input_dim, num_hidden)\n",
        "    self.relu1 = Relu()\n",
        "    self.relu2 = Relu()\n",
        "    self.linear2 = Linear(num_hidden, ouput_dim)\n",
        "  \n",
        "  def __call__(self, x):\n",
        "    l1 = self.linear1(x)\n",
        "    r1 = self.relu1(l1, dropout_rate=0.01)\n",
        "    r2 = self.relu2(r1, dropout_rate=0)\n",
        "    l2 = self.linear2(r2)\n",
        "    return l2\n",
        "  \n",
        "  def backward(self, output_gradient):\n",
        "    linear2_gradient = self.linear2.backward(output_gradient)\n",
        "    relu2_gradient = self.relu2.backward(linear2_gradient)\n",
        "    relu1_gradient = self.relu1.backward(relu2_gradient)\n",
        "    linear1_gradient = self.linear1.backward(relu1_gradient)\n",
        "    # print('Model backward', linear2_gradient.shape, relu_gradient.shape, linear1_gradient.shape)\n",
        "    # import pdb; pdb.set_trace()\n",
        "    return linear1_gradient\n",
        "\n",
        "  def update(self, lr):\n",
        "    self.linear2.update(lr)\n",
        "    self.linear1.update(lr)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nom5WmLlv23I"
      },
      "source": [
        "####Three dimention non-linear input generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lk7wuooGv1KC",
        "outputId": "77ea7856-83d2-447d-f7d6-5b8286b103b6"
      },
      "source": [
        "import sys, numpy as np\n",
        "from keras.datasets import mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "images, labels = (x_train[0:10000].reshape(10000,28*28) / 255, y_train[0:10000])\n",
        "\n",
        "one_hot_labels = np.zeros((len(labels),10))\n",
        "for i,l in enumerate(labels):\n",
        "    one_hot_labels[i][l] = 1\n",
        "labels = one_hot_labels\n",
        "\n",
        "test_images = x_test.reshape(len(x_test),28*28) / 255\n",
        "test_labels = np.zeros((len(y_test),10))\n",
        "for i,l in enumerate(y_test):\n",
        "    test_labels[i][l] = 1\n",
        "print(f'images: {images.shape}, labels: {labels.shape}, test_images: {test_images.shape}, test_labels: {test_labels.shape}')\n",
        "\n",
        "x, y_true = images, labels\n",
        "x_test, y_test = test_images, test_labels"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "images: (10000, 784), labels: (10000, 10), test_images: (10000, 784), test_labels: (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XSfu9DoeRKb"
      },
      "source": [
        "# dropout_mask = np.random.binomial(1, 0.8, size=x1.shape)\n",
        "# dropout_mask"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAjQw-_1x4cI"
      },
      "source": [
        "####Initialize nonlinear and loss for three dimention data\n",
        "\n",
        "3-d input and 2-d output with 2 hidden layers, 10 neurons for hidden layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-TBs0O2x4cS",
        "outputId": "5e1f047e-9e78-4a0c-b8f1-dd7acd338c41"
      },
      "source": [
        "loss = MSE()\n",
        "nonlinear = Model(784, 200, 10)\n",
        "x = images\n",
        "y_true = labels\n",
        "\n",
        "y_pred = nonlinear(x)\n",
        "#print(x.shape, weights_true.shape, y_true.shape, y_pred.shape)\n",
        "print(loss(y_pred, y_true))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.5003188127846059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57nZEGSHwt-Q"
      },
      "source": [
        "####Train three dimention data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRkPypmiwtY1"
      },
      "source": [
        "#fit(x, y_true, model=nonlinear, loss=loss, lr=0.1, num_epochs=1000)\n",
        "\n",
        "#y_pred = nonlinear(x)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXZ4a53-TLCP",
        "outputId": "6a72fd48-23db-4c2a-babc-eb3c64aa8f01"
      },
      "source": [
        "fit_by_batch(x, y_true, x_test, y_test, model=nonlinear, loss=loss, lr=0.01, num_epochs=1000)\n",
        "\n",
        "y_pred = nonlinear(x)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0,loss 0.07830606518955341, correct_rate 0.4888, test_correct_rate 0.6398\n",
            "Epoch 100,loss 0.011405688789719032, correct_rate 0.9597, test_correct_rate 0.9331\n",
            "Epoch 200,loss 0.00864617450428656, correct_rate 0.974, test_correct_rate 0.9406\n",
            "Epoch 300,loss 0.006218858972228003, correct_rate 0.9809, test_correct_rate 0.9429\n",
            "Epoch 400,loss 0.0055890539105505075, correct_rate 0.9851, test_correct_rate 0.9456\n",
            "Epoch 500,loss 0.004341348600221643, correct_rate 0.9878, test_correct_rate 0.9469\n",
            "Epoch 600,loss 0.0038999507108248136, correct_rate 0.9905, test_correct_rate 0.9474\n",
            "Epoch 700,loss 0.003888831363663357, correct_rate 0.9905, test_correct_rate 0.9468\n",
            "Epoch 800,loss 0.0040349626620519155, correct_rate 0.9923, test_correct_rate 0.9476\n",
            "Epoch 900,loss 0.003074088807376177, correct_rate 0.994, test_correct_rate 0.9481\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrdJqjOHl1UG"
      },
      "source": [
        "####Plot the output and the real data using tsne"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RZIf2dIJ6-l"
      },
      "source": [
        "#plot_distribution(x, y_true, y_pred)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGRi5HCiMTHh"
      },
      "source": [
        "#plot_comparison(y_true, y_pred)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwVSwRYgaINb"
      },
      "source": [
        "#plot_3d(x, y_true[:, 0], y_pred=y_pred[:, 0])"
      ],
      "execution_count": 30,
      "outputs": []
    }
  ]
}